ISDEBUG : True # if False, wandb log is used
WANDB :
  PROJECT_NAME : 'Wandb_projectName_a6000' 
  NAME : Wandb_subname_v2 #
MODEL:

  BACKBONE:

    NAME: 'ContentAware'

    VARIANT: 'DoubleLine'

    IMAGE_SIZE: 512

    PRETRAINED_RESNET: False

    IMAGE_KEY: ['image']

    PATCH_KEYS: ['patch_1', 'patch_2']
    
    MASK_KEYS: ['mask_1', 'mask_2']

    FIX_MASK: False

    FEATURE_KEYS: ['feature_1', 'feature_2']

    TARGET_KEYS: ['delta_hat_12', 'delta_hat_21']

  HEAD:

    NAME: 'PerceptualHead'

    PATCH_SIZE: 448
    PATCH_KEYS: ['patch_1', 'patch_2']
    
    # Homography is directly regressed by backbone
    DELTA_HAT_KEYS: ['delta_hat_12', 'delta_hat_21']
    PF_KEYS: []

    # DSAC not required
    RANSAC_HYPOTHESIS_NO: -1
    POINTS_PER_HYPOTHESIS: -1

    # Possible values: resnet18, resnet34, resnet50, resnet101, resnet152, resnext50_32x4d, resnext101_32x8d
    LossNet: 'resnet34'
    # AUXILIARY_RESNET: 'resnet34'
    AUXILIARY_RESNET_OUTPUT_LAYER: 2

    # Triplet loss
    TRIPLET_LOSS: 'double-line'
    TRIPLET_AGGREGATION: 'channel-agnostic'
    TRIPLET_MARGIN: '0.02'
    TRIPLET_DISTANCE: 'l1'
    TRIPLET_MU: 0.01
    MASK_KEYS: ['mask_1','mask_2']
    SAMPLING_STRATEGY: 'upsample-mask'
    MASK_MU: 0.3
DATA:

  # Name of used dataset
  NAME: 'flir'

  # Dataset and camera models root
  DATASET_ROOT: 'dataset/flir_aligned'
    # Train/test split csv files
  TEST_SPLIT: 'dataset/flir_aligned/validation/PreviewData'

  TRAIN_SPLIT: 'dataset/flir_aligned/train/PreviewData'

  # Data transforms & args
  TRANSFORMS: [Multispectral_HomographyNetPrep: [32, 448, ['image_1', 'image_2'], 32, '4_points',True,[0.5, 0.5]],
          #  DictToGrayscale: [['patch_1', 'patch_2']],
           DictToRGB: [['patch_1', 'patch_2', 'nopd_patch_2']],
           DictToTensor: [['patch_1', 'patch_2', 'nopd_patch_2']]]

  TEST_TRANSFORM: [Multispectral_HomographyNetPrep_test: [32, 448, ['image_1', 'image_2'], 0, '4_points', None, None],
                  #  DictToGrayscale: [['patch_1', 'patch_2','image_1', 'image_2']],
                   DictToRGB: [['patch_1', 'patch_2', 'image_1', 'image_2']],
                   DictToTensor: [['patch_1', 'patch_2','image_1', 'image_2']],
                  Key_change: []]

  # Num workers
  NUM_WORKERS: 8

  # SAMPLER PART
  SAMPLER:

    # Number of images in the batch
    BATCH_SIZE: 64

    # How many images we would call one epoch
    TRAIN_SAMPLES_PER_EPOCH: 230400  # 3600 steps for batch_size=64

    # How many images we would call one epoch
    TEST_SAMPLES_PER_EPOCH: 2304  # 36 steps for batch_size=64

    # Test seed to make the test more comparable
    TRAIN_SEED: 42

    # Test seed to make the test more comparable
    TEST_SEED: 0

SOLVER:

  DEVICE: 'cuda'

  OPTIMIZER: 'Adam'
  MOMENTUM_1: 0.9
  MOMENTUM_2: 0.999

  LR: 0.001

  NUM_EPOCHS: 16
  
  MILESTONES: [30000, 60000, 90000]
  LR_DECAY: 0.1
  LOSS: 'biHomE'

LOGGING:
  DIR: 'log/Wandb_subname_v2'
  STEP: 360
  VERBOSE: False

